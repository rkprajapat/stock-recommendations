{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries for stock analysis\n",
    "import pandas as pd\n",
    "import holidays\n",
    "import matplotlib.pyplot as plt\n",
    "import scienceplots\n",
    "from datetime import date, datetime, timedelta\n",
    "import os\n",
    "from IPython.display import display\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import asyncio\n",
    "import time\n",
    "import concurrent.futures\n",
    "\n",
    "from nsetools import Nse\n",
    "nse = Nse()\n",
    "\n",
    "from nsepy import get_history\n",
    "\n",
    "pd.set_option('display.max_columns',None)\n",
    "pd.set_option('display.max_rows',None)\n",
    "pd.set_option('display.width',1000)\n",
    "pd.set_option('display.colheader_justify','center')\n",
    "pd.set_option('display.precision',3)\n",
    "\n",
    "plt.style.use('science')\n",
    "pd.options.plotting.backend = \"plotly\"\n",
    "\n",
    "%matplotlib widget\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-07 13:57:22,839 - distributed.diskutils - INFO - Found stale lock file and directory '/var/folders/h3/wz_ny1xx6vn1bff8_7dlzl0h0000gp/T/dask-worker-space/worker-0okg8fjg', purging\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://127.0.0.1:8787/status\n"
     ]
    }
   ],
   "source": [
    "# import libraries for dask\n",
    "from dask.distributed import Client, LocalCluster\n",
    "import dask.dataframe as dd\n",
    "from dask.delayed import delayed\n",
    "\n",
    "# create dask local cluster\n",
    "cluster = LocalCluster(n_workers=4, threads_per_worker=1, memory_limit='2GB')\n",
    "\n",
    "client = Client(cluster)\n",
    "\n",
    "# print dask dashboard link\n",
    "print(client.dashboard_link)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download historical stock data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check today's date and check if its market holiday\n",
    "def check_market_holiday():\n",
    "    today = pd.to_datetime('today').date()\n",
    "    india_holidays = holidays.India()\n",
    "    if today in india_holidays:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "# get the stock data from yahoo finance if its not a market holiday\n",
    "def get_stock_data(stock_code, latest=True):\n",
    "    if check_market_holiday():\n",
    "        print('Market Holiday')\n",
    "        return None\n",
    "    else:\n",
    "        # check if its a valid stock code and not a market holiday\n",
    "        if nse.is_valid_code(stock_code) and check_market_holiday() == False:\n",
    "            # create a filename for stock data\n",
    "            stock_file = f'historical\\{stock_code}.xlsx'\n",
    "            \n",
    "            # create empty dataframe for stock data\n",
    "            stock_data = pd.DataFrame()\n",
    "            start_date = None\n",
    "            \n",
    "            # check if stock_file exists\n",
    "            if os.path.exists(stock_file):\n",
    "                # load existing stock data from excel file\n",
    "                stock_data = pd.read_excel(f'historical/{stock_code}.xlsx', index_col='Date')\n",
    "                \n",
    "                if len(stock_data) == 0:\n",
    "                    print(f'No Stock Data for {stock_code}')\n",
    "                    # calculate start date to date from last date\n",
    "                    start_date = date.today() - timedelta(days=365*2)\n",
    "                else:\n",
    "                    # return stock_data if latest is False\n",
    "                    if latest == False:\n",
    "                        return stock_data\n",
    "                    \n",
    "                    # get the last date from the stock data\n",
    "                    last_date = stock_data.index[-1]\n",
    "                    \n",
    "                    # check if last_date is today\n",
    "                    if last_date == pd.to_datetime('today').date():\n",
    "                        print(f'{stock_code}: Stock Data is up to date')\n",
    "                        return stock_data\n",
    "            \n",
    "                    # calculate start date to date from last date\n",
    "                    start_date = last_date + timedelta(days=1)\n",
    "                    \n",
    "                    # convert start_date to datetime.date\n",
    "                    start_date = start_date.date()\n",
    "                    \n",
    "            \n",
    "            \n",
    "            # if there is no start_date, create a start_date that is 2 years ago\n",
    "            if start_date == None:\n",
    "                start_date = date.today() - timedelta(days=365*2)\n",
    "\n",
    "            # print(f'Getting Stock Data for {stock_code} from {start_date} to {date.today()}')\n",
    "            \n",
    "            # get the stock data\n",
    "            new_stock_data = get_history(symbol=stock_code, start=start_date, end=date.today())\n",
    "\n",
    "            # print total number of rows in stock_data\n",
    "            # print(f'Total Rows: {len(new_stock_data)}')\n",
    "            \n",
    "            # append the stock data to existing stock data\n",
    "            stock_data = stock_data.append(new_stock_data)\n",
    "            \n",
    "            # return stock_data\n",
    "            return stock_data\n",
    "        else:\n",
    "            print('Invalid Stock Code')\n",
    "            \n",
    "\n",
    "# get_stock_data('SBIN')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download all stocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Stock Codes: 1870\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tasks Completed:   0%|          | 0/1870 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "# write a function to load the data from excel file\n",
    "STOCK_FILE = 'data/stock_codes.xlsx'\n",
    "\n",
    "# check if stock data exists\n",
    "async def is_stock_data_loaded(stock_code, latest=True):\n",
    "    stock_data = get_stock_data(stock_code, latest=latest)\n",
    "\n",
    "    # check if historical directory exists\n",
    "    if not os.path.exists('historical'):\n",
    "        # create historical directory\n",
    "        os.mkdir('historical')\n",
    "\n",
    "        # check if directory was created\n",
    "        if not os.path.exists('historical'):\n",
    "            return False\n",
    "\n",
    "    if stock_data is None or len(stock_data) == 0:\n",
    "        return False\n",
    "\n",
    "    # create a filename for stock data\n",
    "    stock_file = f'historical/{stock_code}.xlsx'\n",
    "\n",
    "    # write stock_data to excel file\n",
    "    stock_data.to_excel(stock_file)\n",
    "\n",
    "    # check if file was created\n",
    "    if not os.path.exists(stock_file):\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "# load historical stock data\n",
    "async def load_stock_codes(stock_file=STOCK_FILE):\n",
    "    # read stock_file into pandas dataframe\n",
    "    df_stock_codes = pd.read_excel(stock_file)\n",
    "\n",
    "    # display the count of stock_codes\n",
    "    print(f'Total Stock Codes: {len(df_stock_codes)}')\n",
    "\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=4) as executor:\n",
    "        loop = asyncio.get_event_loop()\n",
    "        loop.set_default_executor(executor)\n",
    "        tasks = [loop.create_task(is_stock_data_loaded(stock_code)) for stock_code in df_stock_codes['ticker'].tolist()]\n",
    "        for f in tqdm(asyncio.as_completed(tasks), total=len(tasks), desc='Tasks Completed'):\n",
    "            await f\n",
    "\n",
    "await load_stock_codes()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stock Portfolio"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "35554e2c047f53495ecf498b55c8266e254a2deed92865a73f9b63c518b54222"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
